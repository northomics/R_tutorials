---
title: "Stats in R"
output: learnr::tutorial
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr)
knitr::opts_chunk$set(echo = FALSE)
```


## Linear regression

Now that we've got the hang of some R functions, let's do some real analysis!

### What is linear regression? 

- explains the linear relationship between dependent (Y) and independent (X) variables 
- "line of best fit" to data
- a "simple" linear regression is equivalent to a *correlation*
- can be considered *supervised* machine learning technique ([see here](http://machinelearningmastery.com/linear-regression-for-machine-learning/))
    - the model learns from known data, and can be used to predict
    - sometimes we are looking for trends and don't care about predictions

linear regression takes the linear equation of:

$$ Y = mX + b $$
But we're going to use it more like:

$$ \hat{y_{i}} = \hat{\beta_{0}} + \hat{\beta_{1}}x_{i} + \epsilon_{i}$$

where:  
$\hat{y_{i}} =$ predicted response for an experimental unit $i$  
$x_{i} =$ predictor (or independent variable) of experimental unit $i$  
$\hat{\beta_{0}} =$ is expected value when $x_{i} = 0$ (intercept)  
$\hat{\beta_{1}} =$ slope  
$\epsilon =$ some error, because models are never perfect!  

[//]: $\hat{\beta_{0}}$ and $\hat{\beta_{1}}$ are unknown


[//]: **$\beta_{0}$ and $\beta_{1}$: what we have to estimate**

$\beta_{0}$ and $\beta_{1}$ are unknown. We will *estimate these coefficients* from known data.
To do this, we need to estimate a line of best fit than minimizes error... this is where *linear regression* comes in!

## Load some data!

We have options for loading data. 

1. We read use `read.csv()` to read in data from a file.  
2. We can use a built-in dataset from an R package.

Today we'll use a built in dataset called the [palmerpenguins](https://allisonhorst.github.io/palmerpenguins/index.html) dataset. 


```{r penguin, echo = FALSE, out.width = "100%", fig.cap = "Artwork by @allison_horst."}
knitr::include_graphics("images/penguins.png")
```



```{r dataloading, exercise=TRUE}
# install the package, normally required
# install.packages("palmerpenguins")
# load the package
library(palmerpenguins)
# call the data from the package
data(package = 'palmerpenguins') 
head(penguins)
```

We will focus on two penguin measurements for today:

```{r penguinmeasures, echo = FALSE, out.width = "100%", fig.cap = "Artwork by @allison_horst."}
knitr::include_graphics("images/measurements.png")
```


## Linear regression with data

Ok, let's look at the data to see if a linear model looks reasonable...


### Simple visual check

```{r penguincor, exercise=TRUE}
plot(penguins$bill_length_mm, penguins$bill_depth_mm, 
     main="Bill length vs bill depth", xlab = "Bill length (mm)", ylab = "
     Bill depth (mm)")
```

Hmmm... not sure yet. But! Remember! There are **three** types of penguins in the data. Maybe we'll see some patterns later on...

## Setting up a linear regression

Let's estimate the coefficients we were talking about earlier.

- `lm()` is the linear model function. 
- `formula` and `data` are parameters

Try using this code. What does `summary()` give us? What does `abline()` do?

```{r linearmodel, exercise=TRUE}
lm1 <- lm(formula = bill_length_mm ~ bill_depth_mm, data = penguins)
summary(lm1)
plot(penguins$bill_length_mm, penguins$bill_depth_mm, 
     main="Bill length vs bill depth", xlab = "Bill length (mm)", ylab = "
     Bill depth (mm)")
abline(lm1, col="purple")
```

### Summary output

Our summary output gives us a lot of information:

1. Info about distribution of residuals (errors)
2. The estimates of our coefficients
3. Standard error of coefficient estimates
    - square root of the variance 
      - $\sqrt{\sigma}^{2}$
3. t-values (coefficient estimates/standard error)
3. $R^{2}$ = (want closer to 1)
4. p-values 
    - testing if your coefficient = 0


```{r quizlm}
quiz(
  question("Look back at the summary. Does it seem like our linear model is a good fit to our data?",
    answer("Yes!! Look at the coefficient p-value!"),
    answer("Nope. Check out the line of best fit and the $R^{2}$", correct=T)
  )
)
```


## Linear models with more coefficients

OK, so maybe all penguins don't follow the same bill length to depth patterns. How about we test if the type of penguin has an effect on this pattern? We can add this information to our linear model using a different `formula=` parameter, but we have to formulate it on our own. 

We have some options on possible formulas for the linear regression:

* length ~ depth + species 
    * $\hat{length_{i}} = \hat{\beta_{0}} + \hat{\beta_{1}}depth_{i} + \hat{\beta_{2}}species_{i} + \epsilon_{i}$ 
* length ~ depth:species  
    * $\hat{length_{i}} = \hat{\beta_{0}} + \hat{\beta_{2}}species_{i}depth_{i} + \epsilon_{i}$ 
* length ~ depth*species = length ~ depth + species + depth x species 
    * $\hat{length_{i}} = \hat{\beta_{0}} + \hat{\beta_{1}}depth_{i} + \hat{\beta_{2}}species_{i} + \hat{\beta_{2}}species_{i}depth_{i} + \epsilon_{i}$ 

## Your first exercise    
 
OK, so we can run all of these functions, but how do we know what the output is? How can we look at coefficients, error estimate, etc?

Here's your chance to show off! Type how you would print out this information we need and then click on Run Code.

```{r lm_coefficients, exercise=TRUE, exercise_eval=T}
lm2 <- lm(formula = bill_length_mm ~ bill_depth_mm + species, data = penguins)
lm3 <- lm(formula = bill_length_mm ~ bill_depth_mm:species, data = penguins)
lm4 <- lm(formula =bill_length_mm ~ bill_depth_mm*species, data = penguins)
```

```{r lm_coefficients-solution}
lm2 <- lm(formula = bill_length_mm ~ bill_depth_mm + species, data = penguins)
lm3 <- lm(formula = bill_length_mm ~ bill_depth_mm:species, data = penguins)
lm4 <- lm(formula = bill_length_mm ~ bill_depth_mm*species, data = penguins)

summary(lm2)
summary(lm3)
summary(lm4)
```

How can we interpret these linear models? 

*Let's discuss*

## Differences in penguins

Before we get into the fun part (data visualization!) , how about we try some more simple stats.

Let's say that we wanted to show a professor that two penguin species differ in mean body weight. We hypothesize that the Chinstrap penguins have a different mean body weight than the Gentoo penguins.

```{r quizstat}
quiz(
  question("What type of statistical test can we do to test hypothesis?",
    answer("Linear model"),
    answer("Student t-test", correct=T),
    answer("ANOVA"),
    answer("We can just look at the means and decide")
  )
)
```


### Finding the mean bodyweight of penguins

We have a pretty big dataset of info on penguins. We don't really need all of it, do we? Right now we're only interested in body weight info of Chinstrap and Gentoo penguins.

We're going to have to subset our data so that we can focus on what we're interested in right now. We are going to be using the function `filter()`. To do this, we're also going to have to learn about "logical operators". 

You will use logical operators often in R programming. Here are some examples:

- `==`: equals
- `!=`: does not equal
- `&`: AND
- `|`: OR
- `>`: greater than
- `>`: less than
- `>=`: greater or equal to
- `<=`: less than or equal to

Today we want to filter for Chinstrap OR (`|`) Gentoo penguins. It might seem like we're interested in Chinstrap AND (`&`) Gentoo penguins, but in programming logic, that is impossible. **Let's discuss why.**.

```{r filter, exercise=TRUE}
library(tidyverse)
## filtering for Chinstrap OR Gentoo penguins from the species
penguin_chin_gent <- filter(data = penguins, species == "Chinstrap" | species == "Gentoo")
# print the first couple rows
head(penguin_chin_gent)
```

Now, we're only interested in the bod yweight of the penguins. We should make an even smaller dataset that only includes the body weight information of Gentoo and Chinstrap penguins. We're using the function `select()`. `select()` is special and **always** uses the first argument as the data, so we don't need to tell it! Fun.  


```{r select, exercise=T}
## what are the column names of our dataset again? Let's check
colnames(penguin_chin_gent)

## OK, so body weight is callled "body_mass_g". Let's select body_mass_g and species so that we
## can calculate the mean body weight of each species.
penguin_chin_gent_bw <- select(penguin_chin_gent, species, body_mass_g)
```




## Mini intro to `ggplot2`

`ggplot2` is a great package for visualizing all types of data. I think it's more useful to learn how to use `ggplot2` than the "built-in" plotting functions in R. In my opinion, it is more intuitive.... but that's all up for debate. 

We're going to learn how to use ``ggplot2` to plot using our penguin and some of the hypothesis testing we just did. 

```{r ggplot-intro, exercise=T}
library(ggplot2)
```



### How is 


```{r ggplotpenguin, exercise=T}
library(ggplot2)
(bill_len_dep <- ggplot(data = penguins,
                         aes(x = bill_length_mm,
                             y = bill_depth_mm,
                             group = species)) +
  geom_point(aes(color = species, 
                 shape = species),
             size = 3,
             alpha = 0.8) +
  geom_smooth(method = "lm", se = FALSE, aes(color = species)) +
  theme_minimal() +
  scale_color_manual(values = c("darkorange","purple","cyan4")) +
  labs(x = "Bill length (mm)",
       y = "Bill depth (mm)",
       color = "Penguin species",
       shape = "Penguin species") +
  theme(legend.position = c(0.85, 0.15),
        legend.background = element_rect(fill = "white", color = NA),
        plot.title.position = "plot",
        plot.caption = element_text(hjust = 0, face= "italic"),
        plot.caption.position = "plot"))

```


## Your exercise 

Now that we've learned how to:

1. Filter data
2. Select relevant columns
3. Test our hypotheses
4. Visualize our data

**It's time for you to complete some of this on your own!**

Your task:
Come up with your own hypothesis using the penguin dataset and write it out. Choose a statistical test (*hint: it can be one we used already*). Complete your statistical test. Visualize your data using `ggplot2`. 


```{r testing-stats, exercise=T}
### Use this space to complete your exercise.



```